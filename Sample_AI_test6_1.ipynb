{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "#from bs4 import Beautiful Soup  ㅋㅋㅋㅋㅋ\n",
    "# from nltk.corpus import Beautiful Soup\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "import konlp\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#헤더추가 (title,content,time)\n",
    "\n",
    "# train1 =pd.read_csv('test6.csv', engine='python',sep=\",\" ,header=None)\n",
    "train1 =pd.read_csv('test6.csv', engine='python',sep=\",\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>사진</th>\n",
       "      <th>조여정</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>프로필</td>\n",
       "      <td>국세청</td>\n",
       "      <td>과장</td>\n",
       "      <td>전보</td>\n",
       "      <td>자</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>조이</td>\n",
       "      <td>영화제</td>\n",
       "      <td>참석</td>\n",
       "      <td>봉준호</td>\n",
       "      <td>감독</td>\n",
       "      <td>진원</td>\n",
       "      <td>작가</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사진</td>\n",
       "      <td>클라라</td>\n",
       "      <td>시선</td>\n",
       "      <td>올킬</td>\n",
       "      <td>블루</td>\n",
       "      <td>롱</td>\n",
       "      <td>드레스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사진</td>\n",
       "      <td>개</td>\n",
       "      <td>부문</td>\n",
       "      <td>노미네이트</td>\n",
       "      <td>기생충</td>\n",
       "      <td>봉준호</td>\n",
       "      <td>감독</td>\n",
       "      <td>환호</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>사진</td>\n",
       "      <td>함소원</td>\n",
       "      <td>입장</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    사진  조여정 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7  \\\n",
       "0  프로필  국세청         과장         전보          자        NaN        NaN        NaN   \n",
       "1   조이  영화제         참석        봉준호         감독         진원         작가        NaN   \n",
       "2   사진  클라라         시선         올킬         블루          롱        드레스        NaN   \n",
       "3   사진    개         부문      노미네이트        기생충        봉준호         감독         환호   \n",
       "4   사진  함소원         입장        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12 Unnamed: 13  \n",
       "0        NaN        NaN         NaN         NaN         NaN         NaN  \n",
       "1        NaN        NaN         NaN         NaN         NaN         NaN  \n",
       "2        NaN        NaN         NaN         NaN         NaN         NaN  \n",
       "3        NaN        NaN         NaN         NaN         NaN         NaN  \n",
       "4        NaN        NaN         NaN         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2872, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of          사진     조여정 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \\\n",
       "0       프로필     국세청         과장         전보          자        NaN        NaN   \n",
       "1        조이     영화제         참석        봉준호         감독         진원         작가   \n",
       "2        사진     클라라         시선         올킬         블루          롱        드레스   \n",
       "3        사진       개         부문      노미네이트        기생충        봉준호         감독   \n",
       "4        사진     함소원         입장        NaN        NaN        NaN        NaN   \n",
       "5        조이     엄태구         지적         남자        NaN        NaN        NaN   \n",
       "6        조이      진기          주         매력         미모        NaN        NaN   \n",
       "7        조이     기생충        이정은         엄마         미소        NaN        NaN   \n",
       "8        조이      공명        영화제          빛         미소        NaN        NaN   \n",
       "9        조이     영화제        조여정          칸         반한         미소        NaN   \n",
       "10       조이     영화제         문지         민트         여신        NaN        NaN   \n",
       "11       사진      공명         훈남         매력        NaN        NaN        NaN   \n",
       "12       무역       위         전기       프라이팬        특허권         침해        불공정   \n",
       "13       사진  베이비페이스        이성경         변신        NaN        NaN        NaN   \n",
       "14       사진     클라라        NaN        NaN        NaN        NaN        NaN   \n",
       "15       사진      상체         노출        클라라         이보          더          수   \n",
       "16       조이     조여정        영화제      여우주연상         자태        NaN        NaN   \n",
       "17       조이     함소원         연하         남편          향         마음        NaN   \n",
       "18       사진     영화제         참석        기생충        봉준호         감독        NaN   \n",
       "19       사진     이정은         영화          팬        여러분         사랑        NaN   \n",
       "20       사진      문지         섹시         레드          립        NaN        NaN   \n",
       "21       사진     하지영        여배우        NaN        NaN        NaN        NaN   \n",
       "22       사진     김강현        영화제        NaN        NaN        NaN        NaN   \n",
       "23       사진      공명         하트        NaN        NaN        NaN        NaN   \n",
       "24       조이       빈         블랙        드레스        NaN        NaN        NaN   \n",
       "25       조이       빈        영화제         주목         신예        NaN        NaN   \n",
       "26       사진      공명         젠틀        NaN        NaN        NaN        NaN   \n",
       "27       조이      문지         베테        여배우        NaN        NaN        NaN   \n",
       "28       사진       빈         미소        NaN        NaN        NaN        NaN   \n",
       "29       조이     영화제        이성경         금빛         몸매        NaN        NaN   \n",
       "...     ...     ...        ...        ...        ...        ...        ...   \n",
       "2842   스라라넷      인니         교육         제휴        NaN        NaN        NaN   \n",
       "2843      길      복판        고양이          산          채         남성         충격   \n",
       "2844     옥천     복숭아         홍콩         판촉         활동         전개        NaN   \n",
       "2845     올해      휴가         라면         투어         공짜       해외여행        NaN   \n",
       "2846     로드     블루문         펀드      동남아시아         사업         확대         추진   \n",
       "2847     마프     덴마크      비디오아트         특별          전         개최        NaN   \n",
       "2848    에스엘      에프         앤비         킹콩       부대찌개         올해        브랜드   \n",
       "2849     남자     고양이          산          채         엽기         영상      인도네시아   \n",
       "2850   동티모르     아세안         회원          국        NaN        NaN        NaN   \n",
       "2851     부산      병원       컨소시엄        시스템      카자흐스탄          첫         수출   \n",
       "2852     마프      롯데        시네마         홍대         입구        덴마크      비디오아트   \n",
       "2853    블루문      펀드          손         동남         사업         확대         추진   \n",
       "2854    옥천군     복숭아         홍콩         수출         확대         판촉         추진   \n",
       "2855     해외     바이어         초청         수출         상담          회         흥행   \n",
       "2856     광고    여자친구         엄지          똥         머리         스포          티   \n",
       "2857     해외      포토      인도네시아        대통령         손정        NaN        NaN   \n",
       "2858     혈관       폐         음식         부아         메라         오일         효능   \n",
       "2859  슈퍼주니어      규현         출격        NaN        NaN        NaN        NaN   \n",
       "2860     임신       채         고문         구타         당한          듯        시리아   \n",
       "2861      이      주의          새          책        의열단         항일         불꽃   \n",
       "2862     파월       또         우릴         실망        트럼프         맹비         종합   \n",
       "2863     해외      무대         기술         세계         최초         제품        러브콜   \n",
       "2864   금리인하      물꼬         우리         린다        NaN        NaN        NaN   \n",
       "2865     전남     테크노         파크         전남       모빌리티         산업        활성화   \n",
       "2866     이슈     온라인      인도네시아        서비스         종료        NaN        NaN   \n",
       "2867     포토    양해각서         체결        NaN        NaN        NaN        NaN   \n",
       "2868     옥천     복숭아         홍콩         시장         공략        NaN        NaN   \n",
       "2869     애인      혼전        성관계         때문         여성         처벌        NaN   \n",
       "2870     부산      병원         개발         의료         영상         저장         전송   \n",
       "2871  인도네시아      수출         상담          등         쾌거        NaN        NaN   \n",
       "\n",
       "     Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12  \\\n",
       "0           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "1           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "3            환호        NaN        NaN         NaN         NaN         NaN   \n",
       "4           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "5           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "6           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "7           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "8           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "9           NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "10          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "11          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "12           무역         행위         조사          개시         NaN         NaN   \n",
       "13          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "14          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "15          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "16          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "17          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "18          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "19          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "20          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "21          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "22          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "23          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "24          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "25          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "26          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "27          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "28          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "29          NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "...         ...        ...        ...         ...         ...         ...   \n",
       "2842        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2843        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2844        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2845        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2846        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2847        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2848         대상         연속         수상         NaN         NaN         NaN   \n",
       "2849         충격        NaN        NaN         NaN         NaN         NaN   \n",
       "2850        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2851        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2852         특별          전         개최         NaN         NaN         NaN   \n",
       "2853        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2854        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2855         성공         예감        NaN         NaN         NaN         NaN   \n",
       "2856         완벽         소화        NaN         NaN         NaN         NaN   \n",
       "2857        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2858          및        부작용       뉴기니섬          고산         NaN         NaN   \n",
       "2859        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2860         난민          촌         인니          여성          사망         NaN   \n",
       "2861        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2862          보        NaN        NaN         NaN         NaN         NaN   \n",
       "2863        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2864        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2865         기업         간담          회          개최         NaN         NaN   \n",
       "2866        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2867        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2868        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2869        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "2870        시스템      카자흐스탄        맹활약         NaN         NaN         NaN   \n",
       "2871        NaN        NaN        NaN         NaN         NaN         NaN   \n",
       "\n",
       "     Unnamed: 13  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "5            NaN  \n",
       "6            NaN  \n",
       "7            NaN  \n",
       "8            NaN  \n",
       "9            NaN  \n",
       "10           NaN  \n",
       "11           NaN  \n",
       "12           NaN  \n",
       "13           NaN  \n",
       "14           NaN  \n",
       "15           NaN  \n",
       "16           NaN  \n",
       "17           NaN  \n",
       "18           NaN  \n",
       "19           NaN  \n",
       "20           NaN  \n",
       "21           NaN  \n",
       "22           NaN  \n",
       "23           NaN  \n",
       "24           NaN  \n",
       "25           NaN  \n",
       "26           NaN  \n",
       "27           NaN  \n",
       "28           NaN  \n",
       "29           NaN  \n",
       "...          ...  \n",
       "2842         NaN  \n",
       "2843         NaN  \n",
       "2844         NaN  \n",
       "2845         NaN  \n",
       "2846         NaN  \n",
       "2847         NaN  \n",
       "2848         NaN  \n",
       "2849         NaN  \n",
       "2850         NaN  \n",
       "2851         NaN  \n",
       "2852         NaN  \n",
       "2853         NaN  \n",
       "2854         NaN  \n",
       "2855         NaN  \n",
       "2856         NaN  \n",
       "2857         NaN  \n",
       "2858         NaN  \n",
       "2859         NaN  \n",
       "2860         NaN  \n",
       "2861         NaN  \n",
       "2862         NaN  \n",
       "2863         NaN  \n",
       "2864         NaN  \n",
       "2865         NaN  \n",
       "2866         NaN  \n",
       "2867         NaN  \n",
       "2868         NaN  \n",
       "2869         NaN  \n",
       "2870         NaN  \n",
       "2871         NaN  \n",
       "\n",
       "[2872 rows x 14 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "사진             object\n",
       "조여정            object\n",
       "Unnamed: 2     object\n",
       "Unnamed: 3     object\n",
       "Unnamed: 4     object\n",
       "Unnamed: 5     object\n",
       "Unnamed: 6     object\n",
       "Unnamed: 7     object\n",
       "Unnamed: 8     object\n",
       "Unnamed: 9     object\n",
       "Unnamed: 10    object\n",
       "Unnamed: 11    object\n",
       "Unnamed: 12    object\n",
       "Unnamed: 13    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "    level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:44:04,422 : INFO : collecting all words and their counts\n",
      "2019-11-20 21:44:04,424 : WARNING : Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "2019-11-20 21:44:04,425 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-20 21:44:04,426 : INFO : collected 23 word types from a corpus of 129 raw words and 14 sentences\n",
      "2019-11-20 21:44:04,427 : INFO : Loading a fresh vocabulary\n",
      "2019-11-20 21:44:04,429 : INFO : effective_min_count=5 retains 9 unique words (39% of original 23, drops 14)\n",
      "2019-11-20 21:44:04,430 : INFO : effective_min_count=5 leaves 113 word corpus (87% of original 129, drops 16)\n",
      "2019-11-20 21:44:04,431 : INFO : deleting the raw counts dictionary of 23 items\n",
      "2019-11-20 21:44:04,433 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2019-11-20 21:44:04,434 : INFO : downsampling leaves estimated 11 word corpus (10.2% of prior 113)\n",
      "2019-11-20 21:44:04,439 : INFO : estimated required memory for 9 words and 300 dimensions: 26100 bytes\n",
      "2019-11-20 21:44:04,441 : INFO : resetting layer weights\n",
      "2019-11-20 21:44:04,443 : INFO : training model with 4 workers on 9 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-11-20 21:44:04,450 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:44:04,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:44:04,452 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:44:04,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:44:04,453 : INFO : EPOCH - 1 : training on 129 raw words (12 effective words) took 0.0s, 2778 effective words/s\n",
      "2019-11-20 21:44:04,459 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:44:04,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:44:04,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:44:04,461 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:44:04,462 : INFO : EPOCH - 2 : training on 129 raw words (8 effective words) took 0.0s, 1819 effective words/s\n",
      "2019-11-20 21:44:04,468 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:44:04,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:44:04,471 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:44:04,472 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:44:04,473 : INFO : EPOCH - 3 : training on 129 raw words (10 effective words) took 0.0s, 1931 effective words/s\n",
      "2019-11-20 21:44:04,481 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:44:04,482 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:44:04,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:44:04,484 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:44:04,485 : INFO : EPOCH - 4 : training on 129 raw words (10 effective words) took 0.0s, 2206 effective words/s\n",
      "2019-11-20 21:44:04,491 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-20 21:44:04,493 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-20 21:44:04,494 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-20 21:44:04,495 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-20 21:44:04,496 : INFO : EPOCH - 5 : training on 129 raw words (9 effective words) took 0.0s, 1547 effective words/s\n",
      "2019-11-20 21:44:04,497 : INFO : training on a 645 raw words (49 effective words) took 0.1s, 955 effective words/s\n",
      "2019-11-20 21:44:04,497 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model= Word2Vec(train1, size=300, window=5, min_count=5, workers=4, sg=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x18e41745630>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glass\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2019-11-20 21:44:13,818 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word '감' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1237acfd834a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"감\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m                 )\n\u001b[1;32m-> 1447\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m         \"\"\"\n\u001b[1;32m-> 1397\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Method will be removed in 4.0.0, use self.wv.wmdistance() instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word '감' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.most_similar(\"감\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glass\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word '사전' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-22607ae509e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_ted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"사전\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m                 )\n\u001b[1;32m-> 1447\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m         \"\"\"\n\u001b[1;32m-> 1397\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Method will be removed in 4.0.0, use self.wv.wmdistance() instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word '사전' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model_ted.most_similar(\"사전\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-20 21:49:41,373 : INFO : saving Word2Vec object under 300features_5minwords_5context, separately None\n",
      "2019-11-20 21:49:41,375 : INFO : not storing attribute vectors_norm\n",
      "2019-11-20 21:49:41,378 : INFO : not storing attribute cum_table\n",
      "2019-11-20 21:49:41,382 : INFO : saved 300features_5minwords_5context\n"
     ]
    }
   ],
   "source": [
    "#위에 껄로 학습완료\n",
    "\n",
    "#모델 하이퍼파라미터를 설정한 내용을 모델 이름에 담는 다면 나중에 참고하기에 좋을 것이다.\n",
    "#모델을 저장하면 Word2Vec.load()를 통해 모델을 다시 사용할 수 있다. \n",
    "model_name=\"300features_5minwords_5context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 결과 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 유사도가 없는 단어 추출\n",
    "model.wv.doesnt_match('감독은 밥을 먹었어'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 유사도가 없는 단어 추출\n",
    "model_ted.wv.doesnt_match('감독은 밥을 먹었어'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 유사도가 없는 단어 추출\n",
    "model.wv.doesnt_match('사진 찍어봐'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 유사한 단어를 추출\n",
    "model.wv.most_similar(\"사진\")\n",
    "\n",
    "# 아래링크의 결과가 나와야함.\n",
    "#https://programmers.co.kr/learn/courses/21/lessons/1698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ted.wv.most_similar(\"사진\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습하기 위해서는 같은 형태의 입력값 만들어야함\n",
    "# 제목마다 단어의 개수가 다르기 때문에 입력값을 하나의 형태로 만들어야함.\n",
    "# 모든 단어의 벡터값에 대해 평균을 내서 제목 하나당 하나의 벡터로 만드는 방법 ????????????????????????????????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하나의 제목에 대해 전체 단어의 평균값 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 하나의 제목에 대해 전체 단어의 평균값 계산\n",
    "\n",
    "#words:단어의 모음인 하나의 리뷰가 들어간다.????????????????????????????????????????\n",
    "#model:word2vec의 모델을 넣는 곳이며, 우리가 학습한 word3vec 모델이 들어간다.\n",
    "#num_features:word2vec으로 임베딩할떼 정했던 벡터의 차원 수를 뜻한다. \n",
    "\n",
    "words=\"사진조여정우아한 플라워원피스 입고\"\n",
    "def get_features(words,model,num_features): #여기서 words모지?\n",
    "    #출력 벡터 초기화\n",
    "    feature_vector=np.zeros((num_features),dtype=np.float32)\n",
    "    \n",
    "    num_words=0\n",
    "    #어휘사전준비\n",
    "    index2word_set=set(model.wv.index2word)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in index2words_set:\n",
    "            num_word +=1\n",
    "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
    "            feature_vector=np.add(feature_vector,mode[w])\n",
    "\n",
    "    #문장의 단어 수 만큼 나누어 단어 벡터의 평균값을 문장 벡터로 함\n",
    "    feature_vector=np.divide(feature_vector,num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 제목에 대해 각 제목의 평균 벡터구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_text: 전체 제목 데이터를 입력하는 인자???????????????????\n",
    "#model:word2vec 모델 입력하는 인자\n",
    "\n",
    "\n",
    "def get_dataset(title_text,model,num_features):\n",
    "    dataset=list()\n",
    "    \n",
    "    for s in title_text:\n",
    "        dataset.append(get_features(s,model,num_features))\n",
    "        \n",
    "    titleFeatureVecs=np.stack(dataset)\n",
    "        \n",
    "    return titleFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titleFeatureVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실제 학습에 사용될 입력값\n",
    " train_data_vecs=get_dataset(train1,model,num_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
